{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1356774a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00dd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Garima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e23550ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"During training, the neuron that outputs zero will have no contribution to the loss.\n",
    "In backpropagation,the gradient of the ReLU function is also zero for negative inputs.\n",
    "So, if this neuron keeps receiving negative inputs, its weights will stop updating ! and it will essentially become inactive or \"dead.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dfade63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During training, the neuron that outputs zero will have no contribution to the loss.\n",
      "In backpropagation,the gradient of the ReLU function is also zero for negative inputs.\n",
      "So, if this neuron keeps receiving negative inputs, its weights will stop updating ! and it will essentially become inactive or \"dead.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0272f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c49a67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d602a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8303b7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During training, the neuron that outputs zero will have no contribution to the loss.',\n",
       " 'In backpropagation,the gradient of the ReLU function is also zero for negative inputs.',\n",
       " 'So, if this neuron keeps receiving negative inputs, its weights will stop updating !',\n",
       " 'and it will essentially become inactive or \"dead.\"']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fd0e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a26ff9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During training, the neuron that outputs zero will have no contribution to the loss.\n",
      "In backpropagation,the gradient of the ReLU function is also zero for negative inputs.\n",
      "So, if this neuron keeps receiving negative inputs, its weights will stop updating !\n",
      "and it will essentially become inactive or \"dead.\"\n"
     ]
    }
   ],
   "source": [
    "for sent in documents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3b835b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word tokenization\n",
    "# Paragraph into words\n",
    "# Sentence into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01b44302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abb2a094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During',\n",
       " 'training',\n",
       " ',',\n",
       " 'the',\n",
       " 'neuron',\n",
       " 'that',\n",
       " 'outputs',\n",
       " 'zero',\n",
       " 'will',\n",
       " 'have',\n",
       " 'no',\n",
       " 'contribution',\n",
       " 'to',\n",
       " 'the',\n",
       " 'loss',\n",
       " '.',\n",
       " 'In',\n",
       " 'backpropagation',\n",
       " ',',\n",
       " 'the',\n",
       " 'gradient',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ReLU',\n",
       " 'function',\n",
       " 'is',\n",
       " 'also',\n",
       " 'zero',\n",
       " 'for',\n",
       " 'negative',\n",
       " 'inputs',\n",
       " '.',\n",
       " 'So',\n",
       " ',',\n",
       " 'if',\n",
       " 'this',\n",
       " 'neuron',\n",
       " 'keeps',\n",
       " 'receiving',\n",
       " 'negative',\n",
       " 'inputs',\n",
       " ',',\n",
       " 'its',\n",
       " 'weights',\n",
       " 'will',\n",
       " 'stop',\n",
       " 'updating',\n",
       " '!',\n",
       " 'and',\n",
       " 'it',\n",
       " 'will',\n",
       " 'essentially',\n",
       " 'become',\n",
       " 'inactive',\n",
       " 'or',\n",
       " '``',\n",
       " 'dead',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93495df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['During', 'training', ',', 'the', 'neuron', 'that', 'outputs', 'zero', 'will', 'have', 'no', 'contribution', 'to', 'the', 'loss', '.']\n",
      "['In', 'backpropagation', ',', 'the', 'gradient', 'of', 'the', 'ReLU', 'function', 'is', 'also', 'zero', 'for', 'negative', 'inputs', '.']\n",
      "['So', ',', 'if', 'this', 'neuron', 'keeps', 'receiving', 'negative', 'inputs', ',', 'its', 'weights', 'will', 'stop', 'updating', '!']\n",
      "['and', 'it', 'will', 'essentially', 'become', 'inactive', 'or', '``', 'dead', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "for sent in documents:\n",
    "    print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "482a4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7744bd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During',\n",
       " 'training',\n",
       " ',',\n",
       " 'the',\n",
       " 'neuron',\n",
       " 'that',\n",
       " 'outputs',\n",
       " 'zero',\n",
       " 'will',\n",
       " 'have',\n",
       " 'no',\n",
       " 'contribution',\n",
       " 'to',\n",
       " 'the',\n",
       " 'loss',\n",
       " '.',\n",
       " 'In',\n",
       " 'backpropagation',\n",
       " ',',\n",
       " 'the',\n",
       " 'gradient',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ReLU',\n",
       " 'function',\n",
       " 'is',\n",
       " 'also',\n",
       " 'zero',\n",
       " 'for',\n",
       " 'negative',\n",
       " 'inputs',\n",
       " '.',\n",
       " 'So',\n",
       " ',',\n",
       " 'if',\n",
       " 'this',\n",
       " 'neuron',\n",
       " 'keeps',\n",
       " 'receiving',\n",
       " 'negative',\n",
       " 'inputs',\n",
       " ',',\n",
       " 'its',\n",
       " 'weights',\n",
       " 'will',\n",
       " 'stop',\n",
       " 'updating',\n",
       " '!',\n",
       " 'and',\n",
       " 'it',\n",
       " 'will',\n",
       " 'essentially',\n",
       " 'become',\n",
       " 'inactive',\n",
       " 'or',\n",
       " '\"',\n",
       " 'dead',\n",
       " '.\"']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f532ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19e545f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05237be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During',\n",
       " 'training',\n",
       " ',',\n",
       " 'the',\n",
       " 'neuron',\n",
       " 'that',\n",
       " 'outputs',\n",
       " 'zero',\n",
       " 'will',\n",
       " 'have',\n",
       " 'no',\n",
       " 'contribution',\n",
       " 'to',\n",
       " 'the',\n",
       " 'loss.',\n",
       " 'In',\n",
       " 'backpropagation',\n",
       " ',',\n",
       " 'the',\n",
       " 'gradient',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ReLU',\n",
       " 'function',\n",
       " 'is',\n",
       " 'also',\n",
       " 'zero',\n",
       " 'for',\n",
       " 'negative',\n",
       " 'inputs.',\n",
       " 'So',\n",
       " ',',\n",
       " 'if',\n",
       " 'this',\n",
       " 'neuron',\n",
       " 'keeps',\n",
       " 'receiving',\n",
       " 'negative',\n",
       " 'inputs',\n",
       " ',',\n",
       " 'its',\n",
       " 'weights',\n",
       " 'will',\n",
       " 'stop',\n",
       " 'updating',\n",
       " '!',\n",
       " 'and',\n",
       " 'it',\n",
       " 'will',\n",
       " 'essentially',\n",
       " 'become',\n",
       " 'inactive',\n",
       " 'or',\n",
       " '``',\n",
       " 'dead',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c10c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
